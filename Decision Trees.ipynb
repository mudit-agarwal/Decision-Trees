{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) It is a classification Algorithm\n",
    "\n",
    "2) It represts a tree-like structure, in which Leaf Nodes are outputs, and all internal nodes are questions. \n",
    "   For Eg, internal nodes will be questions, like is x == 0, if \"yes\" then it moves to another node etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to decide which feature to split on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) We have to decide on which factor to split our decision tree at the start and on all steps of the process\n",
    "\n",
    "2) Ideally we would like to split on all, and then see which gives us the most accurate decision - But this is mot feasible as this is extremely cost-intensive and takes up exponentially\n",
    "\n",
    "3) So we use the greedy approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x_train,x_test,y_train,y_test = train_test_split(iris.data, iris.target , random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to visualize the tree we can do the follwing done in the below cell : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(clf, out_file = None, feature_names=iris.feature_names,class_names=iris.target_names)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_pdf(iris.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(x_train)\n",
    "y_test_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train,y_traint_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disadvantage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Decision Tree has a disadvantage - Decision Tree keeps on building untill it gets pure nodes. \n",
    "\n",
    "Now this leads to very huge trees and another worry is that, it produces nodes so pure that might lead to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to avoid this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) By stopping the tree at a particular stage, k=3 for example, this tree will go only till 3 levels.4\n",
    "\n",
    "  Problems in this - Dont know what value to choose for K. What if I want to go to further levels one one side of the tree and      not the other \n",
    "\n",
    "2) Pruning - Make the whole tree and then remove the parts that you dont want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of pruning is to find the point in the graph before which the the testing accuaracy decreases as the complexity of the tree increases\n",
    "\n",
    "PNG - Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Information Gain - Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to decide which feature to split on\n",
    "\n",
    "Lower the entropy, better it is\n",
    "\n",
    "Drawback : If the node of 50 is split into 50 nodes of 1 each, we will get 0 which is a bad answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note : Images attached are DT1,DT2,DT3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Gain Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= infogain/split info\n",
    "\n",
    "Drawback: Favours pure nodes to rather common sense split. Can cause errors sometimes\n",
    "\n",
    "##### IMG attached as DTGR1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Gini Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the feature which is used always, it is better than entropy and Gain Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower the Gini Index,the better.\n",
    "\n",
    "This is better as the above also help in identifying pure nodes which result in a better split, But a split of 25-25 pure nodes is better than 1-49 split of pure nodes. Entropy helps in finding pure nodes, but it is unable to identify balanced split.\n",
    "This is why GINI index is superior and used inbuilt in sklearn as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMG is GI1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
